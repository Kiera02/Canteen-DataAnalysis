# Load the required libraries
library(nnet)
library(ggplot2)
library(caret)

# Read the CSV data file
respond <- read.csv("Compulsory Elective (Responses) - Form Responses 1.csv")

# Define categories based on Satisfied
respond$categories <- as.factor(cut(respond$Satisfied, breaks = c(0, 2, 4, 6), labels = c("Unsatisfied", "Neutral", "Satisfied"), include.lowest = TRUE, right = TRUE))

# Duplicate with the specific category you want to oversample
category_to_oversample1 <- "Unsatisfied"
unsatisfied_data <- subset(respond, categories == category_to_oversample1)

category_to_oversample2 <- "Satisfied"
satisfied_data <- subset(respond, categories == category_to_oversample2)

category_to_match <- "Neutral" 
neutral_data <- subset(respond, categories == category_to_match)

# Calculate the number of times to duplicate the Unsatisfied data
duplicate_count1 <- nrow(neutral_data) - nrow(unsatisfied_data)
duplicate_count2 <- nrow(neutral_data) - nrow(satisfied_data)

# Randomly duplicate the Unsatisfied data
duplicated_unsatisfied_data <- unsatisfied_data[sample(nrow(unsatisfied_data), size = duplicate_count1, replace = TRUE), ]

duplicated_satisfied_data <- satisfied_data[sample(nrow(satisfied_data), size = duplicate_count2, replace = TRUE), ]

# Add duplicated data back to respond
duplicated_data <- rbind(duplicated_unsatisfied_data, duplicated_satisfied_data)
respond <- rbind(respond, duplicated_data)

category_counts <- table(respond$categories)
print(category_counts)

# Extract independent variables
independent_vars <- respond[, c("Food.Quality", "Service.Quality", "Affordability", "Hygiene", "Food.Options", "Special.Dietary")]

# Define the control parameters for k-fold cross-validation
cv_control <- trainControl(method = "cv", number = 5)

# Combine categories and independent variables into one dataset
model_data <- data.frame(categories=respond$categories, independent_vars)

# Set the random seed
set.seed(123)

# Split the data into training and testing sets (stratified sampling)
test_indices <- c()
for (cat in levels(model_data$categories)) {
  cat_indices <- which(model_data$categories == cat)
  cat_test_indices <- sample(cat_indices, floor(0.2 * length(cat_indices)))
  test_indices <- c(test_indices, cat_test_indices)
}

train_data <- model_data[-test_indices, ]
test_data <- model_data[test_indices, ]

# Build the multinomial model on the oversampled data
model <- multinom(categories ~ ., data = train_data, control = cv_control, maxit = 100)

# Check for model convergence
if (is.null(model$fitted.values)) {
  warning("Model did not converge. Consider increasing 'maxit' or check for issues.")
}

# Make predictions on the test data
predicted_categories <- predict(model, newdata = test_data, type = "class")

# Create a comparison data frame
comparison_df <- data.frame(Predicted = predicted_categories, Real = test_data$categories)
comparison_df$Index <- 1:nrow(comparison_df)

# Plot the predicted and real categories using a line graph
ggplot(comparison_df, aes(x = Index, y = Predicted, group = 1)) +
  geom_line(color = "blue", linetype = "dashed") +
  geom_line(aes(y = Real), color = "red") +
  labs(x = "Index", y = "Category", title = "Predicted vs. Real Categories") +
  scale_y_discrete(limits = c("Unsatisfied", "Neutral", "Satisfied"))  +
  theme_minimal()

# Display a summary of the multinomial model
summary_coef <- summary(model)$coefficients
print(summary_coef)

# Calculate p-value
coef_matrix <- coef(model)
vcov_matrix <- vcov(model) # Get the variance-covariance matrix of the coefficients
std_errors <- sqrt(diag(vcov_matrix))

# Calculate the z-values
z_values <- coef_matrix / std_errors

# Calculate the p-values
p_values <- 2 * (1 - pnorm(abs(z_values)))

# Ensure all vectors have the same length
min_length <- min(length(coef_matrix), length(std_errors), length(p_values))
coef_matrix <- coef_matrix[1:min_length]
std_errors <- std_errors[1:min_length]
p_values <- p_values[1:min_length]

# Combine coefficients, standard errors, and p-values into a matrix
coef_matrix <- cbind(Estimate = coef_matrix, `Std. Error` = std_errors, `P-value` = p_values)

# Print the coefficient matrix
print(coef_matrix)

# Filter coefficients with significant p-values
significant_coeffs <- coef_matrix[coef_matrix[, "P-value"] < 0.05, ]

# Print the significant coefficients
print("Significant Coefficients:")
print(significant_coeffs)

# Calculate the accuracy of the model
accuracy <- mean(predicted_categories == test_data$categories)

